{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOuIEwlgFvo+vyRoGt4MI+o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NicoleLia/Model-Adv/blob/main/FGSM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision.transforms import Compose, Resize, ToTensor\n",
        "from transformers import BertTokenizer\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "5ZV8utzVdD3u"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!7z x /content/data/Flickr8k.zip -o/content/data/Flickr8k"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Un7RGF4KaAAu",
        "outputId": "7e69fdac-34d2-417d-fe72-010d06cca943"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,8 CPUs AMD EPYC 7B12 (830F10),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan /content/data/\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1 file, 1112971163 bytes (1062 MiB)\n",
            "\n",
            "Extracting archive: /content/data/Flickr8k.zip\n",
            " 50% 4096 Open\b\b\b\b\b\b\b\b\b\b\b\b\b\b              \b\b\b\b\b\b\b\b\b\b\b\b\b\b--\n",
            "Path = /content/data/Flickr8k.zip\n",
            "Type = zip\n",
            "Physical Size = 1112971163\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\b  3% 325 - Images/1350811702_2ce7cfd0c5.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  7% 608 - Images/1572286502_64e5c4b920.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 10% 864 - Images/2052953131_30834196fb.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 13% 1114 - Images/2162564553_96de62c7e6.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 16% 1336 - Images/2256133102_e2c8314ecb.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 19% 1548 - Images/2328106090_b7c2725501.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 21% 1746\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b 23% 1941\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b 25% 2115 - Images/250892549_1e06a06a78.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 28% 2291 - Images/2564663851_3a9832e4fc.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 30% 2458 - Images/2623496164_68ffeb5067.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 32% 2619 - Images/2676651833_3bb42bbb32.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 34% 2776 - Images/2726301121_95a2fbd22b.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 36% 2931 - Images/2784408839_53a25a21eb.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 38% 3074 - Images/2839532455_36a7dc4758.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 39% 3215 - Images/2875658507_c0d9ceae90.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 41% 3353 - Images/2911238432_33ec2d8cec.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 43% 3490 - Images/2947274789_a1a35b33c3.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 44% 3626 - Images/2994107810_af56326389.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 46% 3740 - Images/3027365101_3818be6e16.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 47% 3868 - Images/3058439373_9276a4702a.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 49% 3986 - Images/3091580843_178042c50b.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 50% 4108 - Images/3119887967_271a097464.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 52% 4228 - Images/314940358_ec1958dc1d.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 53% 4345 - Images/3174453534_fcc927c647.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 54% 4448 - Images/3198231851_6b1727482b.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 56% 4555 - Images/3217909454_7baa0edbb2.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 57% 4664 - Images/3242263536_a436f19257.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 58% 4774 - Images/3259992722_4c5e895734.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 59% 4877 - Images/3280672302_2967177653.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 60% 4981 - Images/3304712466_18cbdb85fe.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 62% 5087 - Images/3329858093_0ec73f2190.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 63% 5187 - Images/334768700_51c439b9ee.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 64% 5293 - Images/3365348059_9773165302.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 65% 5399 - Images/3393035454_2d2370ffd4.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 67% 5503 - Images/3415178926_909db9400b.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 68% 5606 - Images/3430779304_43a2146f4b.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 69% 5708 - Images/3451523035_b61d79f6a8.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 70% 5805 - Images/3470303255_fbb41b8dd0.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 72% 5902 - Images/3487419819_e3f89444ce.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 73% 5999 - Images/3508882611_3947c0dbf5.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 74% 6096 - Images/3527926597_45af299eee.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 75% 6191 - Images/3544793763_b38546a5e8.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 76% 6286 - Images/3562816250_6e14d436b1.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 77% 6378 - Images/3582920844_2742804f3d.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 79% 6466 - Images/3600221224_945df01247.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 80% 6557 - Images/3619232550_0b1e1fd4e4.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 81% 6644 - Images/3638374272_444f5e0457.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 82% 6732 - Images/3655155990_b0e201dd3c.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 83% 6818 - Images/3675825945_96b2916959.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 84% 6903 - Images/3693961165_9d6c333d5b.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 85% 6987 - Images/371364900_5167d4dd7f.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 86% 7070 - Images/3744832122_2f4febdff6.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 87% 7151 - Images/397725001_e51f7c391c.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 88% 7236\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b 89% 7319 - Images/446291803_2fd4641b99.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 90% 7404 - Images/471402959_0b187560df.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 92% 7487 - Images/491564019_1ca68d16c1.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 93% 7564 - Images/510197538_0a11b94460.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 94% 7643 - Images/53043785_c468d6f931.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 95% 7722 - Images/544122267_e9e0100bc5.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 96% 7804 - Images/632251903_b36701a5e9.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 97% 7885 - Images/751074141_feafc7b16c.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 98% 7964 - Images/846085364_fc9d23df46.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 99% 8042 - Images/952171414_2db16f846f.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEverything is Ok\n",
            "\n",
            "Files: 8092\n",
            "Size:       1118053179\n",
            "Compressed: 1112971163\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initial\n",
        "def load_data(captions_file, img_dir):\n",
        "    df = pd.read_csv(captions_file)\n",
        "    df['image'] = df['image'].apply(lambda x: os.path.join(img_dir, x))\n",
        "\n",
        "    transform = Compose([\n",
        "        Resize((224, 224)),\n",
        "        ToTensor()\n",
        "    ])\n",
        "\n",
        "    xs = []\n",
        "    ys = []\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        image = Image.open(row['image']).convert('RGB')\n",
        "        caption = row['caption']\n",
        "\n",
        "        image = transform(image)\n",
        "\n",
        "        xs.append(image)\n",
        "        ys.append(caption)\n",
        "\n",
        "    return xs, ys\n",
        "\n",
        "img_dir = '/content/data/Flickr8k/Images'\n",
        "captions_file = '/content/data/Flickr8k/captions.txt'\n",
        "xs, ys = load_data(captions_file, img_dir)\n",
        "print(\"Loaded {} images and captions\".format(len(xs)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpiN1tN5z5qP",
        "outputId": "281cc9d3-0148-4e2f-9d01-2ff82f487943"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 40455 images and captions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    images, captions = zip(*batch)\n",
        "    images = torch.stack(images, 0)\n",
        "    captions = pad_sequence(captions, batch_first=True, padding_value=vocab('<pad>'))\n",
        "    return images, captions.float()"
      ],
      "metadata": {
        "id": "PyFlnAqaz9lL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Vocab:\n",
        "    def __init__(self):\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        self.idx = 0\n",
        "        self.add_word('<unk>')\n",
        "        self.add_word('<pad>')\n",
        "\n",
        "    def add_word(self, word):\n",
        "        if word not in self.word2idx:\n",
        "            self.word2idx[word] = self.idx\n",
        "            self.idx2word[self.idx] = word\n",
        "            self.idx += 1\n",
        "\n",
        "    def __call__(self, word):\n",
        "        if word not in self.word2idx:\n",
        "            return self.word2idx['<unk>']\n",
        "        return self.word2idx[word]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.word2idx)\n",
        "\n",
        "vocab = Vocab()"
      ],
      "metadata": {
        "id": "opVT7zKEbWvG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create instance\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, xs, ys, vocab):\n",
        "        self.xs = xs\n",
        "        self.ys = [torch.tensor([vocab(word) for word in y.split()], dtype=torch.long) for y in ys]\n",
        "        self.vocab = vocab\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.xs)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.xs[index], self.ys[index]\n",
        "\n",
        "dataset = Dataset(xs, ys, vocab)\n",
        "print(\"Dataset length:\", len(dataset))\n",
        "x, y = dataset[0]\n",
        "print(\"First item shape:\", x.shape, \"Caption:\", y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTZBlD1ZbYsQ",
        "outputId": "46bbaddf-64c3-4b68-8299-57c5f5c2aff5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset length: 40455\n",
            "First item shape: torch.Size([3, 224, 224]) Caption: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "\n",
        "def collate_fn(batch):\n",
        "    images, captions = zip(*batch)\n",
        "    images = torch.stack(images, 0)\n",
        "    captions = pad_sequence(captions, batch_first=True, padding_value=vocab('<pad>'))\n",
        "    return images, captions\n",
        "\n",
        "loader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "for images, captions in loader:\n",
        "    print(images.shape, captions)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WW5UnusFbmSw",
        "outputId": "dfd20dfd-e23f-4ae9-b8cf-3076e3877b61"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 3, 224, 224]) tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torchvision.models import resnet50\n",
        "\n",
        "class VLM(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(VLM, self).__init__()\n",
        "        resnet = resnet50(pretrained=True)\n",
        "        self.resnet_features = nn.Sequential(*list(resnet.children())[:-2])\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc_img = nn.Linear(2048, 512)  # 图像特征到嵌入维度\n",
        "\n",
        "        self.embed = nn.Embedding(vocab_size, 512)  # 字幕嵌入层\n",
        "        self.transformer = nn.Transformer(\n",
        "            d_model=512,\n",
        "            nhead=8,\n",
        "            num_encoder_layers=3,\n",
        "            num_decoder_layers=3\n",
        "        )\n",
        "        self.output_fc = nn.Linear(512, vocab_size)  # 输出层\n",
        "\n",
        "    def forward(self, images, captions):\n",
        "        img_features = self.resnet_features(images)\n",
        "        img_features = self.avgpool(img_features)\n",
        "        img_features = torch.flatten(img_features, 1)\n",
        "        img_features = self.fc_img(img_features)\n",
        "\n",
        "        caption_features = self.embed(captions)\n",
        "\n",
        "        # 扩展图像特征维度以匹配字幕特征\n",
        "        img_features = img_features.unsqueeze(1).expand(-1, captions.size(1), -1)\n",
        "        caption_features = caption_features.transpose(0, 1)  # [seq_len, batch_size, embed_size]\n",
        "        caption_features = caption_features.transpose(0, 1)  # 转换为 [batch_size, seq_len, embed_size]\n",
        "\n",
        "\n",
        "        transformer_output = self.transformer(img_features, caption_features)\n",
        "        output = self.output_fc(transformer_output)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "PH4mSXvDborV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fgsm_attack(image, epsilon, data_grad):\n",
        "    sign_data_grad = data_grad.sign()\n",
        "    perturbed_image = image + epsilon * sign_data_grad\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "    return perturbed_image"
      ],
      "metadata": {
        "id": "iwMKqC8Sbr1C"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def adversarial_training(model, device, train_loader, optimizer, criterion, epsilon):\n",
        "    model.train()\n",
        "    for images, captions in train_loader:\n",
        "        images, captions = images.to(device), captions.to(device)\n",
        "\n",
        "        outputs = model(images, captions)\n",
        "        loss = criterion(outputs, captions)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        data_grad = images.grad.data\n",
        "\n",
        "        perturbed_data = fgsm_attack(images, epsilon, data_grad)\n",
        "\n",
        "        outputs_perturbed = model(perturbed_data, captions)\n",
        "        loss_perturbed = criterion(outputs_perturbed, captions)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss_perturbed.backward()\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "id": "h_jm4Y47btXi"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Ssj5l-7qd8by"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, device, train_loader, optimizer, criterion, epochs, scheduler, print_every=50, save_path='/content/model/model1'):\n",
        "    model.train()\n",
        "    all_losses = []  # 记录所有损失以便绘图\n",
        "    best_loss = float('inf')\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for i, (images, captions) in enumerate(train_loader):\n",
        "            images, captions = images.to(device), captions.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images, captions[:, :-1])\n",
        "            outputs = outputs.view(-1, outputs.size(-1))\n",
        "            captions = captions[:, 1:].contiguous().view(-1)\n",
        "            loss = criterion(outputs, captions)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            if (i + 1) % print_every == 0:  # 每处理50个批次打印一次\n",
        "                current_loss = total_loss / print_every\n",
        "                all_losses.append(current_loss)  # 将当前计算的平均损失添加到列表\n",
        "                print(f'Epoch {epoch+1}, Batch {i+1}, Partial Loss: {current_loss:.4f}')\n",
        "                total_loss = 0  # 重置部分损失计数器\n",
        "\n",
        "        scheduler.step()  # 更新学习率\n",
        "\n",
        "        # 打印每个epoch的平均损失\n",
        "        epoch_loss = sum(all_losses[-len(train_loader)//print_every:]) / (len(train_loader)//print_every)\n",
        "        print(f'Epoch {epoch+1}, Total Loss: {epoch_loss:.4f}')\n",
        "\n",
        "        if epoch_loss < best_loss:\n",
        "          best_loss = epoch_loss\n",
        "          torch.save(model.state_dict(), save_path)\n",
        "          print(f\"Model improved and saved to {save_path}\")\n",
        "\n",
        "    # 绘制损失图\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(all_losses, marker='o', linestyle='-', color='b')\n",
        "    plt.title('Model Loss During Training')\n",
        "    plt.xlabel('Number of Batches Processed')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "4Mc8KjXZbu6X"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_test(model, device, test_loader, criterion, model_path):\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for images, captions in test_loader:\n",
        "            images, captions = images.to(device), captions.to(device)\n",
        "            outputs = model(images, captions[:, :-1])\n",
        "            outputs = outputs.view(-1, outputs.size(-1))\n",
        "            captions = captions[:, 1:].contiguous().view(-1)\n",
        "            loss = criterion(outputs, captions)\n",
        "            total_loss += loss.item()\n",
        "    average_loss = total_loss / len(test_loader)\n",
        "    print(f'Test Loss: {average_loss:.4f}')\n"
      ],
      "metadata": {
        "id": "6rI3Iefobw2G"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = VLM(len(vocab)).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.95)\n",
        "criterion = torch.nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8IEexypbyy4",
        "outputId": "21195098-a2de-4250-86f9-c1a82fa1e582"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.95)\n",
        "train(model, device, loader, optimizer, criterion, epochs, scheduler, save_path='/content/model/model1')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvdMyYXnb0Jw",
        "outputId": "c76ddee0-21a0-4b4c-e788-bce5240d0efb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Batch 50, Partial Loss: 0.3681\n",
            "Epoch 1, Batch 100, Partial Loss: 0.1409\n",
            "Epoch 1, Batch 150, Partial Loss: 0.1377\n",
            "Epoch 1, Batch 200, Partial Loss: 0.1367\n",
            "Epoch 1, Batch 250, Partial Loss: 0.1384\n",
            "Epoch 1, Batch 300, Partial Loss: 0.1386\n",
            "Epoch 1, Batch 350, Partial Loss: 0.1387\n",
            "Epoch 1, Batch 400, Partial Loss: 0.1370\n",
            "Epoch 1, Batch 450, Partial Loss: 0.1364\n",
            "Epoch 1, Batch 500, Partial Loss: 0.1355\n",
            "Epoch 1, Batch 550, Partial Loss: 0.1386\n",
            "Epoch 1, Batch 600, Partial Loss: 0.1377\n",
            "Epoch 1, Batch 650, Partial Loss: 0.1407\n",
            "Epoch 1, Batch 700, Partial Loss: 0.1355\n",
            "Epoch 1, Batch 750, Partial Loss: 0.1399\n",
            "Epoch 1, Batch 800, Partial Loss: 0.1347\n",
            "Epoch 1, Batch 850, Partial Loss: 0.1388\n",
            "Epoch 1, Batch 900, Partial Loss: 0.1333\n",
            "Epoch 1, Batch 950, Partial Loss: 0.1394\n",
            "Epoch 1, Batch 1000, Partial Loss: 0.1401\n",
            "Epoch 1, Batch 1050, Partial Loss: 0.1387\n",
            "Epoch 1, Batch 1100, Partial Loss: 0.1399\n",
            "Epoch 1, Batch 1150, Partial Loss: 0.1391\n",
            "Epoch 1, Batch 1200, Partial Loss: 0.1371\n",
            "Epoch 1, Batch 1250, Partial Loss: 0.1389\n",
            "Epoch 1, Total Loss: 0.1472\n",
            "Model improved and saved to /content/model/model1\n",
            "Epoch 2, Batch 50, Partial Loss: 0.1355\n",
            "Epoch 2, Batch 100, Partial Loss: 0.1379\n",
            "Epoch 2, Batch 150, Partial Loss: 0.1395\n",
            "Epoch 2, Batch 200, Partial Loss: 0.1375\n",
            "Epoch 2, Batch 250, Partial Loss: 0.1362\n",
            "Epoch 2, Batch 300, Partial Loss: 0.1415\n",
            "Epoch 2, Batch 350, Partial Loss: 0.1355\n",
            "Epoch 2, Batch 400, Partial Loss: 0.1379\n",
            "Epoch 2, Batch 450, Partial Loss: 0.1337\n",
            "Epoch 2, Batch 500, Partial Loss: 0.1355\n",
            "Epoch 2, Batch 550, Partial Loss: 0.1378\n",
            "Epoch 2, Batch 600, Partial Loss: 0.1359\n",
            "Epoch 2, Batch 650, Partial Loss: 0.1329\n",
            "Epoch 2, Batch 700, Partial Loss: 0.1404\n",
            "Epoch 2, Batch 750, Partial Loss: 0.1354\n",
            "Epoch 2, Batch 800, Partial Loss: 0.1395\n",
            "Epoch 2, Batch 850, Partial Loss: 0.1409\n",
            "Epoch 2, Batch 900, Partial Loss: 0.1403\n",
            "Epoch 2, Batch 950, Partial Loss: 0.1429\n",
            "Epoch 2, Batch 1000, Partial Loss: 0.1387\n",
            "Epoch 2, Batch 1050, Partial Loss: 0.1349\n",
            "Epoch 2, Batch 1100, Partial Loss: 0.1365\n",
            "Epoch 2, Batch 1150, Partial Loss: 0.1388\n",
            "Epoch 2, Batch 1200, Partial Loss: 0.1384\n",
            "Epoch 2, Batch 1250, Partial Loss: 0.1414\n",
            "Epoch 2, Total Loss: 0.1434\n",
            "Model improved and saved to /content/model/model1\n",
            "Epoch 3, Batch 50, Partial Loss: 0.1389\n",
            "Epoch 3, Batch 100, Partial Loss: 0.1373\n",
            "Epoch 3, Batch 150, Partial Loss: 0.1381\n",
            "Epoch 3, Batch 200, Partial Loss: 0.1423\n",
            "Epoch 3, Batch 250, Partial Loss: 0.1332\n",
            "Epoch 3, Batch 300, Partial Loss: 0.1371\n",
            "Epoch 3, Batch 350, Partial Loss: 0.1397\n",
            "Epoch 3, Batch 400, Partial Loss: 0.1371\n",
            "Epoch 3, Batch 450, Partial Loss: 0.1378\n",
            "Epoch 3, Batch 500, Partial Loss: 0.1392\n",
            "Epoch 3, Batch 550, Partial Loss: 0.1399\n",
            "Epoch 3, Batch 600, Partial Loss: 0.1376\n",
            "Epoch 3, Batch 650, Partial Loss: 0.1389\n",
            "Epoch 3, Batch 700, Partial Loss: 0.1397\n",
            "Epoch 3, Batch 750, Partial Loss: 0.1383\n",
            "Epoch 3, Batch 800, Partial Loss: 0.1357\n",
            "Epoch 3, Batch 850, Partial Loss: 0.1372\n",
            "Epoch 3, Batch 900, Partial Loss: 0.1361\n",
            "Epoch 3, Batch 950, Partial Loss: 0.1375\n",
            "Epoch 3, Batch 1000, Partial Loss: 0.1330\n",
            "Epoch 3, Batch 1050, Partial Loss: 0.1410\n",
            "Epoch 3, Batch 1100, Partial Loss: 0.1385\n",
            "Epoch 3, Batch 1150, Partial Loss: 0.1436\n",
            "Epoch 3, Batch 1200, Partial Loss: 0.1384\n",
            "Epoch 3, Batch 1250, Partial Loss: 0.1379\n",
            "Epoch 3, Total Loss: 0.1438\n",
            "Epoch 4, Batch 50, Partial Loss: 0.1307\n",
            "Epoch 4, Batch 100, Partial Loss: 0.1381\n",
            "Epoch 4, Batch 150, Partial Loss: 0.1401\n",
            "Epoch 4, Batch 200, Partial Loss: 0.1380\n",
            "Epoch 4, Batch 250, Partial Loss: 0.1380\n",
            "Epoch 4, Batch 300, Partial Loss: 0.1395\n",
            "Epoch 4, Batch 350, Partial Loss: 0.1367\n",
            "Epoch 4, Batch 400, Partial Loss: 0.1365\n",
            "Epoch 4, Batch 450, Partial Loss: 0.1373\n",
            "Epoch 4, Batch 500, Partial Loss: 0.1402\n",
            "Epoch 4, Batch 550, Partial Loss: 0.1374\n",
            "Epoch 4, Batch 600, Partial Loss: 0.1368\n",
            "Epoch 4, Batch 650, Partial Loss: 0.1340\n",
            "Epoch 4, Batch 700, Partial Loss: 0.1358\n",
            "Epoch 4, Batch 750, Partial Loss: 0.1379\n",
            "Epoch 4, Batch 800, Partial Loss: 0.1375\n",
            "Epoch 4, Batch 850, Partial Loss: 0.1368\n",
            "Epoch 4, Batch 900, Partial Loss: 0.1400\n",
            "Epoch 4, Batch 950, Partial Loss: 0.1388\n",
            "Epoch 4, Batch 1000, Partial Loss: 0.1400\n",
            "Epoch 4, Batch 1050, Partial Loss: 0.1400\n",
            "Epoch 4, Batch 1100, Partial Loss: 0.1321\n",
            "Epoch 4, Batch 1150, Partial Loss: 0.1392\n",
            "Epoch 4, Batch 1200, Partial Loss: 0.1430\n",
            "Epoch 4, Batch 1250, Partial Loss: 0.1379\n",
            "Epoch 4, Total Loss: 0.1432\n",
            "Model improved and saved to /content/model/model1\n",
            "Epoch 5, Batch 50, Partial Loss: 0.1398\n",
            "Epoch 5, Batch 100, Partial Loss: 0.1374\n",
            "Epoch 5, Batch 150, Partial Loss: 0.1363\n",
            "Epoch 5, Batch 200, Partial Loss: 0.1380\n",
            "Epoch 5, Batch 250, Partial Loss: 0.1347\n",
            "Epoch 5, Batch 300, Partial Loss: 0.1345\n",
            "Epoch 5, Batch 350, Partial Loss: 0.1364\n",
            "Epoch 5, Batch 400, Partial Loss: 0.1426\n",
            "Epoch 5, Batch 450, Partial Loss: 0.1375\n",
            "Epoch 5, Batch 500, Partial Loss: 0.1405\n",
            "Epoch 5, Batch 550, Partial Loss: 0.1372\n",
            "Epoch 5, Batch 600, Partial Loss: 0.1356\n",
            "Epoch 5, Batch 650, Partial Loss: 0.1363\n",
            "Epoch 5, Batch 700, Partial Loss: 0.1385\n",
            "Epoch 5, Batch 750, Partial Loss: 0.1361\n",
            "Epoch 5, Batch 800, Partial Loss: 0.1418\n",
            "Epoch 5, Batch 850, Partial Loss: 0.1381\n",
            "Epoch 5, Batch 900, Partial Loss: 0.1408\n",
            "Epoch 5, Batch 950, Partial Loss: 0.1357\n",
            "Epoch 5, Batch 1000, Partial Loss: 0.1357\n",
            "Epoch 5, Batch 1050, Partial Loss: 0.1388\n",
            "Epoch 5, Batch 1100, Partial Loss: 0.1348\n",
            "Epoch 5, Batch 1150, Partial Loss: 0.1350\n",
            "Epoch 5, Batch 1200, Partial Loss: 0.1387\n",
            "Epoch 5, Batch 1250, Partial Loss: 0.1383\n",
            "Epoch 5, Total Loss: 0.1431\n",
            "Model improved and saved to /content/model/model1\n",
            "Epoch 6, Batch 50, Partial Loss: 0.1334\n",
            "Epoch 6, Batch 100, Partial Loss: 0.1379\n",
            "Epoch 6, Batch 150, Partial Loss: 0.1385\n",
            "Epoch 6, Batch 200, Partial Loss: 0.1371\n",
            "Epoch 6, Batch 250, Partial Loss: 0.1381\n",
            "Epoch 6, Batch 300, Partial Loss: 0.1384\n",
            "Epoch 6, Batch 350, Partial Loss: 0.1373\n",
            "Epoch 6, Batch 400, Partial Loss: 0.1362\n",
            "Epoch 6, Batch 450, Partial Loss: 0.1387\n",
            "Epoch 6, Batch 500, Partial Loss: 0.1391\n",
            "Epoch 6, Batch 550, Partial Loss: 0.1391\n",
            "Epoch 6, Batch 600, Partial Loss: 0.1361\n",
            "Epoch 6, Batch 650, Partial Loss: 0.1399\n",
            "Epoch 6, Batch 700, Partial Loss: 0.1396\n",
            "Epoch 6, Batch 750, Partial Loss: 0.1405\n",
            "Epoch 6, Batch 800, Partial Loss: 0.1373\n",
            "Epoch 6, Batch 850, Partial Loss: 0.1382\n",
            "Epoch 6, Batch 900, Partial Loss: 0.1359\n",
            "Epoch 6, Batch 950, Partial Loss: 0.1325\n",
            "Epoch 6, Batch 1000, Partial Loss: 0.1385\n",
            "Epoch 6, Batch 1050, Partial Loss: 0.1332\n",
            "Epoch 6, Batch 1100, Partial Loss: 0.1394\n",
            "Epoch 6, Batch 1150, Partial Loss: 0.1374\n",
            "Epoch 6, Batch 1200, Partial Loss: 0.1407\n",
            "Epoch 6, Batch 1250, Partial Loss: 0.1311\n",
            "Epoch 6, Total Loss: 0.1429\n",
            "Model improved and saved to /content/model/model1\n",
            "Epoch 7, Batch 50, Partial Loss: 0.1372\n",
            "Epoch 7, Batch 100, Partial Loss: 0.1356\n",
            "Epoch 7, Batch 150, Partial Loss: 0.1397\n",
            "Epoch 7, Batch 200, Partial Loss: 0.1412\n",
            "Epoch 7, Batch 250, Partial Loss: 0.1402\n",
            "Epoch 7, Batch 300, Partial Loss: 0.1410\n",
            "Epoch 7, Batch 350, Partial Loss: 0.1346\n",
            "Epoch 7, Batch 400, Partial Loss: 0.1371\n",
            "Epoch 7, Batch 450, Partial Loss: 0.1382\n",
            "Epoch 7, Batch 500, Partial Loss: 0.1333\n",
            "Epoch 7, Batch 550, Partial Loss: 0.1355\n",
            "Epoch 7, Batch 600, Partial Loss: 0.1359\n",
            "Epoch 7, Batch 650, Partial Loss: 0.1374\n",
            "Epoch 7, Batch 700, Partial Loss: 0.1392\n",
            "Epoch 7, Batch 750, Partial Loss: 0.1345\n",
            "Epoch 7, Batch 800, Partial Loss: 0.1407\n",
            "Epoch 7, Batch 850, Partial Loss: 0.1339\n",
            "Epoch 7, Batch 900, Partial Loss: 0.1346\n",
            "Epoch 7, Batch 950, Partial Loss: 0.1389\n",
            "Epoch 7, Batch 1000, Partial Loss: 0.1398\n",
            "Epoch 7, Batch 1050, Partial Loss: 0.1326\n",
            "Epoch 7, Batch 1100, Partial Loss: 0.1420\n",
            "Epoch 7, Batch 1150, Partial Loss: 0.1397\n",
            "Epoch 7, Batch 1200, Partial Loss: 0.1397\n",
            "Epoch 7, Batch 1250, Partial Loss: 0.1366\n",
            "Epoch 7, Total Loss: 0.1428\n",
            "Model improved and saved to /content/model/model1\n",
            "Epoch 8, Batch 50, Partial Loss: 0.1373\n",
            "Epoch 8, Batch 100, Partial Loss: 0.1371\n",
            "Epoch 8, Batch 150, Partial Loss: 0.1371\n",
            "Epoch 8, Batch 200, Partial Loss: 0.1383\n",
            "Epoch 8, Batch 250, Partial Loss: 0.1365\n",
            "Epoch 8, Batch 300, Partial Loss: 0.1374\n",
            "Epoch 8, Batch 350, Partial Loss: 0.1391\n",
            "Epoch 8, Batch 400, Partial Loss: 0.1417\n",
            "Epoch 8, Batch 450, Partial Loss: 0.1364\n",
            "Epoch 8, Batch 500, Partial Loss: 0.1388\n",
            "Epoch 8, Batch 550, Partial Loss: 0.1398\n",
            "Epoch 8, Batch 600, Partial Loss: 0.1380\n",
            "Epoch 8, Batch 650, Partial Loss: 0.1328\n",
            "Epoch 8, Batch 700, Partial Loss: 0.1355\n",
            "Epoch 8, Batch 750, Partial Loss: 0.1377\n",
            "Epoch 8, Batch 800, Partial Loss: 0.1364\n",
            "Epoch 8, Batch 850, Partial Loss: 0.1361\n",
            "Epoch 8, Batch 900, Partial Loss: 0.1388\n",
            "Epoch 8, Batch 950, Partial Loss: 0.1349\n",
            "Epoch 8, Batch 1000, Partial Loss: 0.1352\n",
            "Epoch 8, Batch 1050, Partial Loss: 0.1385\n",
            "Epoch 8, Batch 1100, Partial Loss: 0.1395\n",
            "Epoch 8, Batch 1150, Partial Loss: 0.1359\n",
            "Epoch 8, Batch 1200, Partial Loss: 0.1371\n",
            "Epoch 8, Batch 1250, Partial Loss: 0.1383\n",
            "Epoch 8, Total Loss: 0.1428\n",
            "Epoch 9, Batch 50, Partial Loss: 0.1356\n",
            "Epoch 9, Batch 100, Partial Loss: 0.1339\n",
            "Epoch 9, Batch 150, Partial Loss: 0.1387\n",
            "Epoch 9, Batch 200, Partial Loss: 0.1349\n",
            "Epoch 9, Batch 250, Partial Loss: 0.1382\n",
            "Epoch 9, Batch 300, Partial Loss: 0.1354\n",
            "Epoch 9, Batch 350, Partial Loss: 0.1366\n",
            "Epoch 9, Batch 400, Partial Loss: 0.1366\n",
            "Epoch 9, Batch 450, Partial Loss: 0.1383\n",
            "Epoch 9, Batch 500, Partial Loss: 0.1357\n",
            "Epoch 9, Batch 550, Partial Loss: 0.1382\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "load_and_test(model, device, loader, criterion, '/content/model/model1')"
      ],
      "metadata": {
        "id": "rXnLpPCGb7XA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}